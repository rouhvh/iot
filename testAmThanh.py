from flask import Flask, render_template, Response
import cv2
import numpy as np
import time
import datetime
import os
from threading import Thread, Lock
from playsound import playsound
import platform
from gtts import gTTS
import tempfile
import pygame
import threading
import sys
from PIL import ImageFont, ImageDraw, Image

if platform.system() == "Windows":
    import winsound

app = Flask(__name__)

stream_url = 'http://192.168.137.66:4747/video/'
cap = cv2.VideoCapture(stream_url)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

fps = 25
width, height = 320, 240
video_frame = None
lock = Lock()
capture_path = "captured_images"
os.makedirs(capture_path, exist_ok=True)

EYE_CLOSED_DURATION_THRESHOLD = 2
EYE_PIXEL_THRESHOLD = 12
closed_start_time = None

alert_audio = "alarm.mp3"
FONT_PATH = "arial.ttf"

alert_playing = False
last_alert_time = 0
ALERT_COOLDOWN = 5  

pygame.mixer.init()

def draw_text_vietnamese(img, text, position, color=(0, 255, 0)):
    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)
    font = ImageFont.truetype(FONT_PATH, 24)
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

def play_alert_sound():
    global alert_playing, last_alert_time
    if time.time() - last_alert_time < ALERT_COOLDOWN:
        return  
    last_alert_time = time.time()
    try:
        if os.path.exists(alert_audio):
            playsound(alert_audio)
        else:
            print("‚ö† Kh√¥ng t√¨m th·∫•y file √¢m thanh, ph√°t beep thay th·∫ø.")
            if platform.system() == "Windows":
                winsound.Beep(1000, 500)
    except Exception as e:
        print("L·ªói khi ph√°t √¢m thanh c·∫£nh b√°o:", e)
    finally:
        alert_playing = False

def sendWarning(text):
    global alert_playing, last_alert_time
    if alert_playing or (time.time() - last_alert_time < ALERT_COOLDOWN):
        return  
    alert_playing = True
    
    def play_audio():
        global alert_playing
        try:
            tts = gTTS(text=text, lang="vi")
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio_file:
                temp_audio_path = temp_audio_file.name
                tts.save(temp_audio_path)
            pygame.mixer.music.load(temp_audio_path)
            pygame.mixer.music.play()
            while pygame.mixer.music.get_busy():
                pygame.time.wait(100)
            pygame.mixer.music.stop()
            os.remove(temp_audio_path)  # Ch·ªâ x√≥a sau khi nh·∫°c ph√°t xong
        except Exception as e:
            print(f"L·ªói √¢m thanh: {e}", file=sys.stderr)
        finally:
            alert_playing = False
    
    threading.Thread(target=play_audio, daemon=True).start()

def capture_image(frame):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(capture_path, f"alert_{timestamp}.jpg")
    cv2.imwrite(filename, frame)
    print(f"üì∏ ·∫¢nh ƒë√£ ƒë∆∞·ª£c l∆∞u: {filename}")

def reconnect_camera():
    global cap
    cap.release()
    time.sleep(2)
    cap = cv2.VideoCapture(stream_url)

def draw_text_vietnamese(img, text, position, color=(0, 255, 0), font_size=16):
    """H√†m v·∫Ω ch·ªØ h·ªó tr·ª£ ti·∫øng Vi·ªát v·ªõi k√≠ch th∆∞·ªõc font c√≥ th·ªÉ thay ƒë·ªïi."""
    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)
    font = ImageFont.truetype(FONT_PATH, font_size)  # üî• Th√™m font_size v√†o ƒë√¢y
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

def camera_stream():
    global video_frame, closed_start_time
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö† M·∫•t k·∫øt n·ªëi camera, ƒëang th·ª≠ k·∫øt n·ªëi l·∫°i...")
            reconnect_camera()
            time.sleep(0.5)
            continue

        frame = cv2.resize(frame, (width, height))
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

        eye_closed = False
        show_warning = False

        for (x, y, w, h) in faces:
            roi_gray = gray[y:y+h, x:x+w]
            roi_color = frame[y:y+h, x:x+w]

            # üìå **Ph√°t hi·ªán m·∫Øt**
            eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5)

            closed_count = 0  # ƒê·∫øm s·ªë m·∫Øt nh·∫Øm
            for (ex, ey, ew, eh) in eyes:
                if eh < EYE_PIXEL_THRESHOLD:  
                    closed_count += 1  

            eye_closed = closed_count == len(eyes)  

            # üìå **X√°c ƒë·ªãnh th·ªùi gian m·∫Øt nh·∫Øm**
            current_time = time.time()
            if eye_closed:
                if closed_start_time is None:
                    closed_start_time = current_time  # B·∫Øt ƒë·∫ßu t√≠nh th·ªùi gian
                elapsed_time = current_time - closed_start_time
                if elapsed_time >= EYE_CLOSED_DURATION_THRESHOLD:
                    show_warning = True  # B·∫≠t c·∫£nh b√°o
            else:
                closed_start_time = None  # Reset khi m·∫Øt m·ªü l·∫°i

            # üìå **V·∫Ω khung m·∫Øt d·ª±a v√†o tr·∫°ng th√°i**
            for (ex, ey, ew, eh) in eyes:
                eye_x, eye_y, eye_w, eye_h = x + ex, y + ey, ew, eh
                
                if eye_closed:
                    if show_warning:
                        color = (0, 0, 255)  # üî¥ **M·∫Øt nh·∫Øm ‚â• 2s ‚Üí Khung ƒë·ªè**
                    else:
                        color = (0, 255, 255)  # üü° **M·∫Øt nh·∫Øm < 2s ‚Üí Khung v√†ng**
                else:
                    color = (0, 255, 0)  # ‚úÖ **M·∫Øt m·ªü ‚Üí Khung xanh**
                
                cv2.rectangle(frame, (eye_x, eye_y), (eye_x + eye_w, eye_y + eye_h), color, 2)

            # üìå **V·∫Ω khung m·∫∑t v√† c·∫£nh b√°o**
            if show_warning:  # üî¥ **M·∫Øt nh·∫Øm qu√° 2s ‚Üí C·∫£nh b√°o**
                frame = draw_text_vietnamese(frame, "NGUY HI·ªÇM!", (x + 5, y - 10), (255, 0, 0))  # üü• Ch·ªØ ƒë·ªè
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)  # üü• Khung m·∫∑t ƒë·ªè
                sendWarning("B·∫°n ƒëang bu·ªìn ng·ªß, h√£y t·ªânh t√°o!")
                capture_image(frame)
            elif eye_closed:  # üü° **M·∫Øt nh·∫Øm nh∆∞ng ch∆∞a qu√° 2s**
                frame = draw_text_vietnamese(frame, "M·∫Øt nh·∫Øm - Kh√¥ng b√¨nh th∆∞·ªùng", (x + 5, y - 10), (255, 255, 0))  # üü° Ch·ªØ v√†ng
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)  # üü° Khung m·∫∑t v√†ng
            else:  # ‚úÖ **M·∫Øt m·ªü**
                frame = draw_text_vietnamese(frame, "M·∫Øt m·ªü - B√¨nh th∆∞·ªùng", (x + 5, y - 10), (0, 255, 0))  # ‚úÖ Ch·ªØ xanh
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)  # ‚úÖ Khung m·∫∑t xanh

            break  # Ch·ªâ x·ª≠ l√Ω khu√¥n m·∫∑t ƒë·∫ßu ti√™n

        with lock:
            video_frame = frame.copy()


def gen_frames():
    global video_frame
    while True:
        with lock:
            if video_frame is None:
                time.sleep(0.1)
                continue
            ret, buffer = cv2.imencode('.jpg', video_frame)
            if not ret:
                continue
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/')
def index():
    return render_template('index_flask_server.html')

if __name__ == '__main__':
    camera_thread = Thread(target=camera_stream, daemon=True)
    camera_thread.start()
    try:
        app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
    finally:
        if cap.isOpened():
            cap.release()
